{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels as stm\n",
    "import scipy.stats\n",
    "File_List = ['UCI_ionosphere_Normalized','UCI_iris_Normalized','UCI_wine_Normalized','UCI_glass_Normalized','UCI_parkinsons_Normalized','UCI_sonar-all_Normalized','UCI_vehicle_Normalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI_ionosphere_Normalized\n",
      "AHP_UCI_ionosphere.csv\n",
      "UCI_iris_Normalized\n",
      "AHP_UCI_iris.csv\n",
      "UCI_wine_Normalized\n",
      "AHP_UCI_wine.csv\n",
      "UCI_glass_Normalized\n",
      "AHP_UCI_glass.csv\n",
      "UCI_parkinsons_Normalized\n",
      "AHP_UCI_parkinsons.csv\n",
      "UCI_sonar-all_Normalized\n",
      "AHP_UCI_sonar-all.csv\n",
      "UCI_vehicle_Normalized\n",
      "AHP_UCI_vehicle.csv\n"
     ]
    }
   ],
   "source": [
    "for file in File_List:\n",
    "    filename = file+'.csv'\n",
    "    DataFrame = pd.read_csv(filename)\n",
    "    \n",
    "    class_num = DataFrame['class'].max() + 1 \n",
    "    #print(class_num)\n",
    "    D_List = []\n",
    "    S_List = []\n",
    "    for feature in DataFrame:\n",
    "        if feature == 'class' : continue\n",
    "        mean_List = []\n",
    "        std_List = []\n",
    "        for i in range(class_num):\n",
    "            s_by_class = DataFrame[feature][DataFrame['class'] == i]\n",
    "            mean_List.append(s_by_class.mean())  \n",
    "            std_List.append(s_by_class.std())\n",
    "        #print(mean_List)\n",
    "    #count D value\n",
    "        D_value = 0\n",
    "        for i in range(len(mean_List)):\n",
    "            for j in range(len(mean_List)):\n",
    "                if i == j : continue\n",
    "                D_value += abs(mean_List[i]-mean_List[j])\n",
    "        D_List.append(D_value)\n",
    "    #count S value :\n",
    "        S_J = np.std(std_List)\n",
    "        S_value = S_J/(sum(std_List)/class_num)\n",
    "        S_List.append(S_value)\n",
    "    #print(D_List)\n",
    "    #print(np.isnan(S_List[1]))\n",
    "    #count C1,C2 matrix\n",
    "    feature_num = len(D_List)\n",
    "    C1 = np.eye(feature_num,feature_num)\n",
    "    C2 = np.eye(feature_num,feature_num)\n",
    "    for i in range(feature_num-1):\n",
    "        for j in range(i+1,feature_num):\n",
    "            if i == j : continue\n",
    "            if D_List[i] == 0 :\n",
    "                C1[i][j] = 0\n",
    "                C1[j][i] = 99999\n",
    "            elif D_List[j] == 0:\n",
    "                C1[i][j] = 99999\n",
    "                C1[j][i] = 0\n",
    "            else:\n",
    "                C1[i][j] = D_List[i] / D_List[j]\n",
    "                C1[j][i] = 1/ C1[i][j]\n",
    "                \n",
    "            if S_List[i] == 0 or np.isnan(S_List[i]) :\n",
    "                C2[i][j] = 0\n",
    "                C2[j][i] = 99999\n",
    "            elif S_List[j] == 0 or np.isnan(S_List[j]):\n",
    "                C2[i][j] = 0\n",
    "                C2[j][i] = 99999\n",
    "            else:\n",
    "                C2[i][j] = S_List[i] / S_List[j]\n",
    "                C2[j][i] = 1/ C2[i][j]\n",
    "    #print(C1,C2)       \n",
    "    #normalize C1 ,C1\n",
    "    #print((C2[:,1]))\n",
    "    for j in range(feature_num):\n",
    "        column_sum_1 = sum(C1[:,j])\n",
    "        column_sum_2 = sum(C2[:,j])\n",
    "        #print(column_sum_1)\n",
    "        for i in range(feature_num):\n",
    "            C1[i,j] = C1[i,j] / column_sum_1\n",
    "            C2[i,j] = C2[i,j] / column_sum_2\n",
    "    #print(C1,C2)       \n",
    "    \n",
    "    CV1 = []\n",
    "    CV2 = []\n",
    "    for i in range(feature_num):\n",
    "        CV1.append(np.mean(C1[i]))\n",
    "        CV2.append(np.mean(C2[i]))\n",
    "    #print('CV1 : \\n',CV1)\n",
    "    #print('CV2 : \\n',CV2)\n",
    "    FC1 = np.matrix([CV1,CV2]).T\n",
    "    FC2 = np.matrix([CV2,CV1]).T\n",
    "    #print('FC \\n',FC)\n",
    "    #criteria preference by GC\n",
    "    Nc = 2\n",
    "    St = [np.std(CV1),np.std(CV2)]\n",
    "    alpha = 0.01\n",
    "    p_max = 1\n",
    "    #print(FC)\n",
    "    if feature_num >4 :\n",
    "        try:\n",
    "            res1 = stm.tsa.stattools.grangercausalitytests(FC1,p_max,verbose = False)\n",
    "            res2 = stm.tsa.stattools.grangercausalitytests(FC2,p_max,verbose = False)\n",
    "            F = [res1[1][0]['ssr_ftest'][0],res2[1][0]['ssr_ftest'][0]]\n",
    "            cv = [scipy.stats.f.ppf(q=1-alpha, dfn=res1[1][0]['ssr_ftest'][3], dfd=res1[1][0]['ssr_ftest'][2]),scipy.stats.f.ppf(q=1-alpha, dfn=res2[1][0]['ssr_ftest'][3], dfd=res2[1][0]['ssr_ftest'][2])]\n",
    "        except:\n",
    "            F = [0,0]\n",
    "            cv = [scipy.stats.f.ppf(q=1-alpha, dfn=1, dfd=0),scipy.stats.f.ppf(q=1-alpha, dfn=1, dfd=0)]\n",
    "    \n",
    "    else:\n",
    "        F = [0,0]\n",
    "        cv = [scipy.stats.f.ppf(q=1-alpha, dfn=1, dfd=0),scipy.stats.f.ppf(q=1-alpha, dfn=1, dfd=0)]\n",
    "    \n",
    "    #print(F,cv)\n",
    "    P = np.eye(Nc,Nc)\n",
    "    for i in range(0,Nc-1):\n",
    "        Wp = 0\n",
    "        for j in range(i+1,Nc):\n",
    "            if St[i] > St[j]: Wp = St[i] / St[j]\n",
    "            else: Wp = St[j] / St[i]\n",
    "            #print(Wp)\n",
    "            if F[i] > F[j] and F[i] > cv[i] :\n",
    "                P[i,j] = Wp\n",
    "                P[j,i] = 1/Wp\n",
    "            else:\n",
    "                P[j,i] = Wp\n",
    "                P[i,j] = 1/Wp\n",
    "    #normalized             \n",
    "    for j in range(Nc):\n",
    "        column_sum = sum(P[:,j])\n",
    "        #print(column_sum)\n",
    "        for i in range(Nc):\n",
    "            P[i,j] = P[i,j] / column_sum\n",
    "    #print(P)\n",
    "    PV = [] \n",
    "    for i in range(Nc):\n",
    "        PV.append(np.mean(P[i]))\n",
    "    #print(PV)\n",
    "    PV = np.matrix(PV)\n",
    "    W = FC1 * PV.T\n",
    "    #print('W',file,W.T,end = '\\n\\n')\n",
    "    #print((W[0,0]))\n",
    "    #print(W[2,0])\n",
    "    \n",
    "    Result_DataFrame = pd.DataFrame()\n",
    "    for i,feature in enumerate(DataFrame):\n",
    "        if feature == 'class':\n",
    "            Result_DataFrame[feature] = DataFrame[feature]\n",
    "        else:\n",
    "            Result_DataFrame[feature] = DataFrame[feature].apply(lambda x : x*W[i,0])\n",
    "    #print('DataFrame \\n',DataFrame.head(3))\n",
    "    #print('Result \\n',Result_DataFrame.head(3))\n",
    "    print(file)\n",
    "    \n",
    "    outfile_name = 'AHP_'+file.replace('_Normalized','')+'.csv'\n",
    "    print(outfile_name)\n",
    "    Result_DataFrame.to_csv(outfile_name,index = False)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
